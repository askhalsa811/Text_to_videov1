{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1741839782694,"user":{"displayName":"Amanpreet singh","userId":"07093958952830411266"},"user_tz":240},"id":"ksouNGStQ6zQ"},"outputs":[],"source":["#making a ai video maker"]},{"cell_type":"markdown","metadata":{"id":"HEcLumKT1Gx-"},"source":["Installing modules"]},{"cell_type":"code","source":["!pip install ffmpeg\n","!pip install ffmpeg-python"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CcAe05RgvIQG","executionInfo":{"status":"ok","timestamp":1741839790906,"user_tz":240,"elapsed":8212,"user":{"displayName":"Amanpreet singh","userId":"07093958952830411266"}},"outputId":"7aba0bca-167f-4748-8c29-e1eae7110f5b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ffmpeg\n","  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: ffmpeg\n","  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6082 sha256=f29dca29c59b1cde2370a91a64ec578b0a5e002ef9392f29754e48b4de7c5199\n","  Stored in directory: /root/.cache/pip/wheels/56/30/c5/576bdd729f3bc062d62a551be7fefd6ed2f761901568171e4e\n","Successfully built ffmpeg\n","Installing collected packages: ffmpeg\n","Successfully installed ffmpeg-1.4\n","Collecting ffmpeg-python\n","  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n","Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n","Installing collected packages: ffmpeg-python\n","Successfully installed ffmpeg-python-0.2.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"LWr9KopniobK","outputId":"8d7230e9-7654-4df5-e9a2-7e079302bc49"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting google-generativeai==0.4.0\n","  Downloading google_generativeai-0.4.0-py3-none-any.whl.metadata (6.2 kB)\n","Collecting google-ai-generativelanguage==0.4.0 (from google-generativeai==0.4.0)\n","  Downloading google_ai_generativelanguage-0.4.0-py3-none-any.whl.metadata (5.1 kB)\n","Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai==0.4.0) (2.38.0)\n","Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai==0.4.0) (2.24.1)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai==0.4.0) (4.25.6)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai==0.4.0) (2.10.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai==0.4.0) (4.67.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai==0.4.0) (4.12.2)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.4.0->google-generativeai==0.4.0) (1.26.0)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai==0.4.0) (1.69.1)\n","Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai==0.4.0) (2.32.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai==0.4.0) (5.5.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai==0.4.0) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai==0.4.0) (4.9)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai==0.4.0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai==0.4.0) (2.27.2)\n","Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai==0.4.0) (1.70.0)\n","Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai==0.4.0) (1.62.3)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai==0.4.0) (0.6.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai==0.4.0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai==0.4.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai==0.4.0) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai==0.4.0) (2025.1.31)\n","Downloading google_generativeai-0.4.0-py3-none-any.whl (137 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.4/137.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading google_ai_generativelanguage-0.4.0-py3-none-any.whl (598 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m598.7/598.7 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: google-ai-generativelanguage, google-generativeai\n","  Attempting uninstall: google-ai-generativelanguage\n","    Found existing installation: google-ai-generativelanguage 0.6.15\n","    Uninstalling google-ai-generativelanguage-0.6.15:\n","      Successfully uninstalled google-ai-generativelanguage-0.6.15\n","  Attempting uninstall: google-generativeai\n","    Found existing installation: google-generativeai 0.8.4\n","    Uninstalling google-generativeai-0.8.4:\n","      Successfully uninstalled google-generativeai-0.8.4\n","Successfully installed google-ai-generativelanguage-0.4.0 google-generativeai-0.4.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]},"id":"02902beee302463a83165a52b81d75be"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.4.0)\n","Requirement already satisfied: google-ai-generativelanguage==0.4.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.4.0)\n","Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n","Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.1)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.25.6)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.10.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.12.2)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.4.0->google-generativeai) (1.26.0)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.69.1)\n","Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.27.2)\n","Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai) (1.70.0)\n","Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai) (1.62.3)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n","Collecting edge-tts\n","  Downloading edge_tts-7.0.0-py3-none-any.whl.metadata (5.2 kB)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (3.11.13)\n","Requirement already satisfied: certifi>=2023.11.17 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (2025.1.31)\n","Collecting srt<4.0.0,>=3.4.1 (from edge-tts)\n","  Downloading srt-3.5.3.tar.gz (28 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tabulate<1.0.0,>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (0.9.0)\n","Requirement already satisfied: typing-extensions<5.0.0,>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (4.12.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (2.5.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (25.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (0.3.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.18.3)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp<4.0.0,>=3.8.0->edge-tts) (3.10)\n","Downloading edge_tts-7.0.0-py3-none-any.whl (23 kB)\n","Building wheels for collected packages: srt\n","  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22428 sha256=01487fa409f0f5ede6f1faea8f4cff415a660bf8c414bc0cfe968125792a1c1c\n","  Stored in directory: /root/.cache/pip/wheels/1f/43/f1/23ee9119497fcb57d9f7046fbf34c6d9027c46a1fa7824cf08\n","Successfully built srt\n","Installing collected packages: srt, edge-tts\n","Successfully installed edge-tts-7.0.0 srt-3.5.3\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m135.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"]}],"source":["#all requiremnts\n","!pip install --upgrade google-generativeai==0.4.0\n","!pip install google-generativeai\n","!pip install edge-tts nest-asyncio\n","# Install required packages\n","!pip install -q git+https://github.com/openai/whisper.git\n","!pip install pysrt\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OSLmTOeDu87-"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qHn--1gUrIcf"},"outputs":[],"source":["import os\n","\n","# Get current working directory\n","current_dir = os.getcwd()\n","\n","# Check if already inside \"scripting\"\n","if os.path.basename(current_dir) == \"scripting\":\n","    print(\"Already inside 'scripting' directory. No action needed.\")\n","else:\n","    # Check if \"scripting\" directory exists\n","    if not os.path.exists(\"scripting\"):\n","        os.makedirs(\"scripting\")  # Create directory if it doesn't exist\n","        print(\"'scripting' directory created.\")\n","    else:\n","        print(\"'scripting' directory already exists.\")\n","\n","    # Change to \"scripting\" directory\n","    os.chdir(\"scripting\")\n","    print(\"Changed working directory to 'scripting'.\")\n"]},{"cell_type":"code","source":["ls"],"metadata":{"id":"uaRoeEgZXCAS"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AERITQM3qzTI"},"outputs":[],"source":["%ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ErZ_-CXmq8zY"},"outputs":[],"source":["%pwd"]},{"cell_type":"markdown","metadata":{"id":"Xj4CntKd1Jf1"},"source":["Importng key"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vsccDsLOi1Hp"},"outputs":[],"source":["# prompt: write  a code to input gemini key in os\n","\n","import os\n","\n","# Set your Gemini API key as an environment variable.\n","# Replace 'YOUR_GEMINI_API_KEY' with your actual key.\n","os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCx-KA9DAFLilicEz4xBmVZ0_nFBigfj-c\"\n","\n","# Now you can use the key in your code, e.g.:\n","api_key = os.environ.get(\"GOOGLE_API_KEY\")\n","# ...rest of your Gemini API usage code...\n","\n","# Verification (optional): print the key to verify it is set correctly\n","# print(api_key) # comment this out if not needed\n"]},{"cell_type":"markdown","metadata":{"id":"t8OQuvh11LfV"},"source":["Raw data input here"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"izRJpa-Xkolf"},"outputs":[],"source":["#raw text input\n","raw_text = \"\"\"\n","DEODORANT\n","3 tablespoons coconut oil\n","2 tablespoons shea butter\n","2 tablespoons beeswax\n","3 tablespoons baking soda\n","3 tablespoons arrowroot powder\n","25 drops essential oils (I like a\n","combination or lavender and tea tree\n","oil, or a odor eliminating blend called\n","\"purify\")\n","Melt the coconut oil, shea butter and\n","beeswax in a double boiler. Remove\n","from the heat and add in the baking\n","soda, arrowroot powder and essential\n","oils.\n","Use a small funnel, to pour the liquid\n","into a deodorant stick. It will harden\n","as it cools. Keep for one year.\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"_282Smkm1PFc"},"source":["Script Making prompts"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4vLw-SqHuctm"},"outputs":[],"source":["prompt_base = \"\"\"You will be given a piece of raw data to analyze. Your task is to determine the main topic, estimate the target audience age range, and identify the targeted demographics based on the content. After your analysis, provide the results in a JSON format.\n","\n","Here is the raw data to analyze:\n","<raw_data>\n","{raw_text}\n","</raw_data>\n","\n","Please follow these steps:\n","\n","1. Carefully read and analyze the content of the raw data.\n","2. Determine the main topic or subject matter being discussed.\n","3. Estimate the target audience age range for this content. Consider the complexity of the language, subject matter, and any explicit mentions of age groups.\n","4. Identify the targeted demographics. This may include factors such as gender, location, interests, occupation, or any other relevant demographic information you can infer from the content.\n","\n","5. Format your findings into a JSON object with the following structure:\n","\n","   {\n","     \"topic\": \"Main topic or subject matter\",\n","     \"target_audience_age\": \"Age range (e.g., '18-35' or '40+')\",\n","     \"targeted_demographics\": [\"demographic1\", \"demographic2\", \"demographic3\"]\n","   }\n","\n","Here's an example of how your output should look:\n","\n","<output>\n","{\n","  \"topic\": \"Sustainable fashion trends\",\n","  \"target_audience_age\": \"18-25\",\n","  \"targeted_demographics\": [\"environmentally conscious consumers\", \"fashion enthusiasts\", \"young professionals\"]\n","}\n","\n","</output>\n","\n","Please provide your analysis and JSON output based on the given raw data.\"\"\"\n","\n","\n","\n","\n","script_writing_prompt=\"\"\"Input Parameters:\n","\n","\n","Duration: 60 seconds\n","Structure:\n","Hook: Start with a compelling opening to grab the listener's attention.\n","Problem: Clearly state the problem or challenge relevant to the topic and audience.\n","Solution: Present a clear, engaging solution that addresses the problem.\n","Prompt Example:\n","\n","\"Using the provided raw data, topic, target audience, and targeted demographics, create a 60-second audio script that includes:\n","\n","A strong, attention-grabbing hook at the beginning.\n","A clear explanation of a key problem or challenge.\n","A compelling solution that resonates with the audience. Ensure the script is engaging, concise, and tailored to the specified demographics.\"\n","This prompt structure will help guide the creation of an effective 60-second audio script with the required elements.\"\"\"\n","\n","\n","final_auido_script = \"\"\"You will be converting a script into an audible script that includes emotion without explicitly describing it. Your task is to transform the input script into a version that can be performed by voice actors, focusing on conveying emotion through tone and pacing rather than descriptive words.\n","\n","Here is the original script:\n","\n","<original_script>\n","{{SCRIPT}}\n","</original_script>\n","\n","To create the audible script:\n","\n","1. Remove any words or phrases that describe actions, emotions, or stage directions. These should be implied through the delivery of the lines rather than stated explicitly.\n","\n","2. Add emotional subtext to the dialogue by considering the context and the characters' feelings. However, do not include written descriptions of these emotions in the script.\n","\n","3. Adjust the pacing and emphasis of the lines to reflect the emotional state of the characters. You can use punctuation, line breaks, or capitalization to indicate how the lines should be delivered, but do not add explicit instructions.\n","\n","4. Ensure that the script flows naturally when read aloud, making any necessary adjustments to sentence structure or word choice to enhance its audibility.\n","\n","5. Do not add any new dialogue or descriptive elements that were not present in the original script.\n","\n","6. Format the audible script using only the characters' names (in all caps) followed by their dialogue. Do not include any other formatting or descriptive elements.\n","\n","Remember, the goal is to create a script that allows voice actors to convey the emotion and action through their performance, without relying on written cues or descriptions.\n","\n","Present your final audible script without any word like\"NARRATOR:\",\"narrtion\" just narration without any of these. Ensure that the script contains only character names and dialogue, with no additional descriptive elements or stage directions.\"\"\"\n","\n","\n","Audio_ready_prompt= \"\"\"You are an expert in audio narration and content restructuring. Your task is to improve the flow and coherence of an audio narration transcript while maintaining its original content and enhancing its emotional impact.\n","\n","Here is the transcript of the audio narration you need to analyze and improve:\n","\n","<audio_transcript>\n","{{final_response.text}}\n","</audio_transcript>\n","\n","Please follow these steps to complete the task:\n","\n","1. Analyze the transcript:\n","   In <narration_breakdown> tags, break down your thought process as you examine the text. Include the following:\n","   a) Identify any contextual anomalies that disrupt the flow (e.g., abrupt topic changes, inconsistent tenses, repetitive information, misplaced details, awkward transitions). Quote specific examples from the transcript.\n","   b) Note any emotional cues or references to music in the original text, providing direct quotes.\n","   c) List the main topics or themes in the narration, numbering them sequentially.\n","   d) Outline a step-by-step plan for restructuring the narration to improve its flow and coherence. Number each step and briefly explain its purpose.\n","\n","2. Restructure the narration:\n","   Based on your analysis, rewrite the entire narration to improve its flow and coherence. Consider the following:\n","   - Organize ideas in a logical sequence\n","   - Ensure smooth transitions between topics\n","   - Maintain perspective throughout\n","   - Remove unnecessary repetition\n","   - Clarify any confusing or ambiguous statements\n","   - Emphasize emotional elements and musical references to enhance the narration's impact\n","\n","   Present the restructured narration within <restructured_narration> tags.\n","3. GIve narration as output no extra word just simple narration with emotion in line.\n","\n","Remember to preserve the original content and meaning while improving the overall structure and flow of the narration. Your goal is to enhance the listening experience without altering the core message, while also amplifying the emotional elements of the piece but htere should be no elemnets in the like  sound or any other thing.\n","\n","your response is restructured narration no explation nothing just what voice actor will speak\n","If you're using a text editor with find-and-replace functionality, you can search for:\n","WARM, FRIENDLY VOICE: (including the space after the colon)\n","and replace it with nothing to clean the script.\"\"\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MiWBojUPdRZW"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PdvpeUKpdT-E"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"LeUfrTdviNJe"},"source":["Topic, target audinece and oter parameter Extractor  . \"add more information in\n","romtp for more parameters\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hfkli3sURD1L"},"outputs":[],"source":["import os\n","import google.generativeai as genai\n","\n","# Retrieve API key from environment variable\n","api_key = os.environ.get(\"GOOGLE_API_KEY\")\n","\n","# Configure the library with your API key\n","genai.configure(api_key=api_key)\n","\n","# Define a basic raw text from which we want to extract the topic\n","#raw_text = \"Your text goes here. Replace this with the actual text you want to analyze.\"\n","\n","# Create a prompt that instructs the model to extract the main topic\n","prompt = f\"rawdata: {raw_text} , prompt: {prompt_base}\"\n","\n","# Generate content using the model\n","model = genai.GenerativeModel('gemini-exp-1206')\n","response = model.generate_content(prompt)\n","\n","# Print the generated response text\n","print(response.text)"]},{"cell_type":"markdown","metadata":{"id":"CPatjsREicxN"},"source":["Making json data correct"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aK1beoYklCxh"},"outputs":[],"source":["# prompt: write a code to take input form response.text . make bad json format good and print json format and save response in variable\n","\n","import os\n","import google.generativeai as genai\n","import json\n","\n","# ... (your existing code) ...\n","\n","# Generate content using the model\n","model = genai.GenerativeModel('gemini-exp-1206')\n","response = model.generate_content(prompt)\n","\n","# Print the generated response text\n","print(response.text)\n","\n","# Extract JSON data from the response\n","try:\n","    # Attempt to directly parse the response\n","    json_data = json.loads(response.text)\n","    print(\"Direct JSON parsing successful.\")\n","    print(json.dumps(json_data, indent=2))  # Print formatted JSON\n","\n","except json.JSONDecodeError:\n","    print(\"Direct JSON parsing failed. Attempting to extract JSON from the text.\")\n","\n","    # Find the start and end of the JSON object\n","    start_index = response.text.find(\"{\")\n","    end_index = response.text.rfind(\"}\")\n","\n","    if start_index != -1 and end_index != -1:\n","      json_string = response.text[start_index : end_index + 1]\n","\n","      try:\n","        # Attempt to parse extracted string\n","        json_data = json.loads(json_string)\n","        print(\"JSON extraction and parsing successful.\")\n","        print(json.dumps(json_data, indent=2)) # Print formatted JSON\n","\n","      except json.JSONDecodeError as e:\n","          print(f\"Error parsing extracted JSON: {e}\")\n","          json_data = None\n","    else:\n","        print(\"Could not find valid JSON in the response text.\")\n","        json_data = None\n","\n","# Save the response to a variable\n","response_data = json_data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z9okUNJb0ixE"},"outputs":[],"source":["# prompt: write a code to take json_data as input ans store into csv file using pandas and also update raw data in csv\n","\n","import pandas as pd\n","\n","def json_to_csv(json_data, filename=\"output.csv\"):\n","    try:\n","        df = pd.DataFrame([json_data])  # Convert JSON to DataFrame\n","        df.to_csv(filename, index=False)  # Save DataFrame to CSV\n","        print(f\"Successfully saved JSON data to {filename}\")\n","    except Exception as e:\n","        print(f\"Error saving JSON to CSV: {e}\")\n","\n","# Example usage (assuming 'response_data' contains your JSON):\n","if 'response_data' in locals() and response_data:\n","  json_to_csv(response_data)\n","else:\n","  print(\"response_data is not defined or empty. Cannot create csv file\")\n","\n","\n","def update_csv_with_raw_text(csv_filepath, raw_text_column_name=\"raw_text\"):\n","    \"\"\"Updates a CSV file with a new column containing the provided raw text.\n","\n","    Args:\n","        csv_filepath: The path to the CSV file.\n","        raw_text_column_name: The name of the new column for raw text.\n","    \"\"\"\n","    try:\n","        # Read the existing CSV file into a pandas DataFrame\n","        df = pd.read_csv(csv_filepath)\n","\n","        # Add a new column with the raw text\n","        df[raw_text_column_name] = raw_text\n","\n","        # Save the updated DataFrame back to the CSV file\n","        df.to_csv(csv_filepath, index=False)\n","        print(f\"Successfully updated {csv_filepath} with raw text.\")\n","    except FileNotFoundError:\n","        print(f\"Error: File not found at {csv_filepath}\")\n","    except Exception as e:\n","        print(f\"An error occurred: {e}\")\n","\n","# Example usage: Assuming 'raw_text' variable is defined\n","# and you want to update the 'output.csv' file\n","update_csv_with_raw_text(\"output.csv\")\n","try:\n","  df = pd.read_csv('output.csv')\n","  print(df)\n","except FileNotFoundError:\n","  print(\"Error: output.csv not found. Please run the code that generates the file first.\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xEyT8DhaBAkz"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AEN1D3_rwJAm"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yaSiLdRKymUn"},"outputs":[],"source":["# prompt: take output.cs and prompt as input and use google gemini  to write script\n","\n","import os\n","import google.generativeai as genai\n","import json\n","import pandas as pd\n","\n","# ... (your existing code) ...\n","\n","# Assuming 'output.csv' exists and contains the JSON data\n","try:\n","    df = pd.read_csv('output.csv')\n","\n","    # Extract data from the DataFrame\n","    topic = df['topic'].iloc[0]\n","    target_audience = df['target_audience_age'].iloc[0]\n","    demographics = df['targeted_demographics'].iloc[0]  # This will be a string\n","\n","    # Convert the demographics string to a list (if needed)\n","    try:\n","        demographics_list = eval(demographics) # Use eval carefully, only if you trust the source of the string.\n","    except (SyntaxError, NameError):\n","        demographics_list = [demographics]  # Handle cases where it's not a valid Python list\n","\n","    script_prompt = f\"\"\"Using the provided information, create a 60-second audio script.\n","\n","    Topic: {topic}\n","    Target Audience: {target_audience}\n","    Targeted Demographics: {demographics_list}\n","    Raw: {raw_text}\n","    prompt : {script_writing_prompt}\n","\n","      \"\"\"\n","\n","    # Generate the script using Gemini\n","    model = genai.GenerativeModel('gemini-exp-1206') # Use a more powerful model if available\n","    script_response = model.generate_content(script_prompt)\n","    print(script_response.text)\n","\n","    #Save the script to a file\n","    with open(\"generated_script.txt\", \"w\") as f:\n","        f.write(script_response.text)\n","\n","\n","except FileNotFoundError:\n","    print(\"Error: output.csv not found. Please run the code that generates the file first.\")\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E7GXdKoMA5e3"},"outputs":[],"source":["# prompt: update  script_response.text in output.csv as script\n","\n","# ... (your existing code) ...\n","\n","# Assuming 'output.csv' exists and contains the JSON data\n","try:\n","    df = pd.read_csv('output.csv')\n","\n","    # ... (your existing code to extract topic, target_audience, demographics)\n","\n","    # Generate the script using Gemini\n","    # ... (your existing code to generate script_response)\n","\n","\n","    # Update the CSV with the script\n","    df['script'] = script_response.text  # Add a new 'script' column\n","    df.to_csv('output.csv', index=False)  # Overwrite the CSV with the updated data\n","\n","    print(\"Successfully updated output.csv with the generated script.\")\n","\n","\n","except FileNotFoundError:\n","    print(\"Error: output.csv not found. Please run the code that generates the file first.\")\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iyrf9hKnMWvn"},"outputs":[],"source":["# prompt: use script from output.csv using pandas. write a audio script using gemini  without any other data\n","\n","try:\n","    df = pd.read_csv('output.csv')\n","\n","    # Extract data from the DataFrame\n","    topic = df['topic'].iloc[0]\n","    target_audience = df['target_audience_age'].iloc[0]\n","    demographics = df['targeted_demographics'].iloc[0]  # This will be a string\n","    raw_text_from_csv = df['raw_text'].iloc[0]\n","\n","    # Convert the demographics string to a list (if needed)\n","    try:\n","        demographics_list = eval(demographics)\n","    except (SyntaxError, NameError):\n","        demographics_list = [demographics]\n","\n","    script_prompt = f\"\"\"Using the provided information, create a 60-second audio script.\n","\n","    Topic: {topic}\n","    Target Audience: {target_audience}\n","    Targeted Demographics: {demographics_list}\n","    Raw: {raw_text_from_csv}\n","    prompt : {script_writing_prompt}\n","\n","      \"\"\"\n","\n","    # Generate the script using Gemini\n","    model = genai.GenerativeModel('gemini-exp-1206')\n","    script_response = model.generate_content(script_prompt)\n","    print(script_response.text)\n","\n","    #Save the script to a file\n","    with open(\"generated_script.txt\", \"w\") as f:\n","        f.write(script_response.text)\n","\n","    # Update the CSV with the script\n","    df['script'] = script_response.text  # Add a new 'script' column\n","    df.to_csv('output.csv', index=False)  # Overwrite the CSV with the updated data\n","\n","    print(\"Successfully updated output.csv with the generated script.\")\n","\n","\n","except FileNotFoundError:\n","    print(\"Error: output.csv not found. Please run the code that generates the file first.\")\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dEoE7cDnNOTE"},"outputs":[],"source":["# prompt: take final_script_prompt and script_response.text as i put and process both by google gmini\n","\n","# ... (your existing code) ...\n","\n","# Assuming 'generated_script.txt' exists and contains the script\n","try:\n","    with open(\"generated_script.txt\", \"r\") as f:\n","        script_content = f.read()\n","\n","    final_prompt = final_auido_script.replace(\"{{SCRIPT}}\", script_content)\n","\n","    model = genai.GenerativeModel('gemini-exp-1206')\n","    final_response = model.generate_content(final_prompt)\n","    print(final_response.text)\n","\n","    # Save the final response\n","    with open(\"final_audio_script.txt\", \"w\") as f:\n","        f.write(final_response.text)\n","\n","    # Update the CSV with the final script\n","    df['final_script'] = final_response.text\n","    df.to_csv('output.csv', index=False)\n","\n","except FileNotFoundError:\n","    print(\"Error: generated_script.txt not found.\")\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zXM2c7P5dVR0"},"outputs":[],"source":["# prompt: use final_response.text and audio_ready_prompt process it with gemini\n","\n","try:\n","    with open(\"final_audio_script.txt\", \"r\") as f:\n","        final_script_content = f.read()\n","\n","    audio_ready_prompt_filled = Audio_ready_prompt.replace(\"{{final_response.text}}\", final_script_content)\n","\n","    model = genai.GenerativeModel('gemini-exp-1206')\n","    audio_ready_response = model.generate_content(audio_ready_prompt_filled)\n","    print(audio_ready_response.text)\n","\n","    # Save the audio ready response\n","    with open(\"audio_ready_script.txt\", \"w\") as f:\n","        f.write(audio_ready_response.text)\n","\n","    # Update the CSV with the audio ready script\n","    df['audio_ready_script'] = audio_ready_response.text\n","    df.to_csv('output.csv', index=False)\n","\n","except FileNotFoundError:\n","    print(\"Error: final_audio_script.txt not found.\")\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U7QrM5Btr9M8"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IiHvR0pioEWe"},"outputs":[],"source":["# prompt: use restructured_narration and google gemini and update the output.csv file audio_gen_script\n","\n","import re\n","\n","# ... (your existing code) ...\n","\n","try:\n","    with open(\"audio_ready_script.txt\", \"r\") as f:\n","        audio_ready_content = f.read()\n","\n","    # Use regex to extract the restructured narration\n","    match = re.search(r\"<restructured_narration>(.*?)</restructured_narration>\", audio_ready_content, re.DOTALL)\n","    if match:\n","        restructured_narration = match.group(1).strip()\n","\n","        #Further cleaning (remove extra lines and spaces)\n","        restructured_narration = re.sub(r\"\\n\\s*\\n\", \"\\n\\n\", restructured_narration) #Remove multiple blank lines\n","        restructured_narration = restructured_narration.replace(\"WARM, FRIENDLY VOICE:\", \"\") #Remove specific phrase\n","\n","\n","        # Update the CSV with the extracted and cleaned narration\n","        df['audio_gen_script'] = restructured_narration\n","        df.to_csv('output.csv', index=False)\n","        print(\"Successfully updated output.csv with the audio generation script.\")\n","    else:\n","        print(\"Could not find <restructured_narration> tags in the audio_ready_script.txt\")\n","\n","except FileNotFoundError:\n","    print(\"Error: audio_ready_script.txt not found.\")\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"12Kzm1FVr_i0"},"outputs":[],"source":["# prompt: update thsi code for low halustionation \"try:\n","#     with open(\"final_audio_script.txt\", \"r\") as f:\n","#         final_script_content = f.read()\n","#     audio_ready_prompt_filled = Audio_ready_prompt.replace(\"{{final_response.text}}\", final_script_content)\n","#     model = genai.GenerativeModel('gemini-exp-1206')\n","#     audio_ready_response = model.generate_content(audio_ready_prompt_filled)\n","#     print(audio_ready_response.text)\n","#     # Save the audio ready response\n","#     with open(\"audio_ready_script.txt\", \"w\") as f:\n","#         f.write(audio_ready_response.text)\n","#     # Update the CSV with the audio ready script\n","#     df['audio_ready_script'] = audio_ready_response.text\n","#     df.to_csv('output.csv', index=False)\n","# except FileNotFoundError:\n","#     print(\"Error: final_audio_script.txt not found.\")\n","# except Exception as e:\n","#     print(f\"An error occurred: {e}\")\n","# \"\n","\n","import os\n","import google.generativeai as genai\n","import json\n","import pandas as pd\n","import re\n","\n","# ... (your existing code) ...\n","\n","try:\n","    with open(\"final_audio_script.txt\", \"r\", encoding=\"utf-8\") as f: #Specify encoding\n","        final_script_content = f.read()\n","\n","    #Check if Audio_ready_prompt is defined\n","    if 'Audio_ready_prompt' not in locals():\n","        raise NameError(\"Audio_ready_prompt is not defined\")\n","\n","    audio_ready_prompt_filled = Audio_ready_prompt.replace(\"{{final_response.text}}\", final_script_content)\n","\n","    model = genai.GenerativeModel('gemini-exp-1206')\n","    audio_ready_response = model.generate_content(audio_ready_prompt_filled)\n","    print(audio_ready_response.text)\n","\n","    # Save the audio ready response\n","    with open(\"audio_ready_script.txt\", \"w\", encoding=\"utf-8\") as f: #Specify encoding\n","        f.write(audio_ready_response.text)\n","\n","    # Check if df is defined before using it\n","    if 'df' not in locals():\n","        print(\"Warning: 'df' DataFrame not found.  Skipping CSV update.\")\n","    else:\n","        try:\n","            df['audio_ready_script'] = audio_ready_response.text\n","            df.to_csv('output.csv', index=False)\n","        except Exception as e:\n","            print(f\"An error occurred while updating the CSV: {e}\")\n","\n","except FileNotFoundError:\n","    print(\"Error: final_audio_script.txt not found.\")\n","except NameError as e:\n","    print(f\"NameError: {e}\")\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ve5ZvcGpqhFR"},"outputs":[],"source":["# prompt: remove all temprary files made while making script and leave output.csv\n","\"\"\"\n","import os\n","# ... (rest of your imports)\n","\n","# ... (your existing code) ...\n","\n","# Remove temporary files (except output.csv)\n","temp_files = [f for f in os.listdir() if f not in [\"output.csv\"]]\n","for f in temp_files:\n","  if os.path.isfile(f):\n","    os.remove(f)\n","    print(f\"Removed file: {f}\")\n","  else:\n","    print(f\"Skipping directory: {f}\")\n","\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"wdI7RjxwkojF"},"source":["Audio gen\n","locally"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BXNhhbJsjQEo"},"outputs":[],"source":["# Install the edge-tts package\n","\n","\n","import asyncio\n","import pandas as pd\n","import edge_tts\n","import nest_asyncio\n","\n","# Apply nest_asyncio to fix the asyncio error in Jupyter/IPython environments\n","nest_asyncio.apply()\n","\n","async def generate_audio(text, output_file, voice=\"en-US-JennyNeural\"):\n","    \"\"\"Generate audio from text using Edge TTS.\"\"\"\n","    try:\n","        communicate = edge_tts.Communicate(text, voice=voice)\n","        await communicate.save(output_file)\n","        print(f\"Audio file '{output_file}' generated successfully.\")\n","        return output_file\n","    except Exception as e:\n","        print(f\"Error generating audio: {e}\")\n","        return None\n","\n","async def main():\n","    try:\n","        # Read the CSV file\n","        df = pd.read_csv('output.csv')\n","\n","        # Check if audio_gen_script column exists\n","        if 'audio_gen_script' not in df.columns:\n","            print(\"Error: 'audio_gen_script' column not found in output.csv.\")\n","            return\n","\n","        # Get the script from the first row\n","        audio_gen_script = df['audio_gen_script'].iloc[0]\n","\n","        # Check if audio_gen_script is not NaN or empty\n","        if pd.isna(audio_gen_script) or not audio_gen_script:\n","            print(\"Warning: 'audio_gen_script' column is empty or NaN in output.csv. Skipping audio generation.\")\n","            return\n","\n","        # Generate audio\n","        await generate_audio(audio_gen_script, \"output.mp3\")\n","\n","    except FileNotFoundError:\n","        print(\"Error: output.csv not found.\")\n","    except IndexError:\n","        print(\"Error: output.csv does not contain any rows.\")\n","    except Exception as e:\n","        print(f\"An unexpected error occurred: {e}\")\n","\n","# Run the main function\n","asyncio.run(main())"]},{"cell_type":"markdown","metadata":{"id":"Edum5enKo_wA"},"source":["Doing Direction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GMD3bBX5n4sf"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"hkd_71IOn4fO"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ejXdTJH7Y4J"},"outputs":[],"source":["\n","import whisper\n","import os\n","import pysrt\n","import datetime\n","import json\n","\n","# Download the Whisper tiny model (much smaller and faster than medium)\n","print(\"Downloading Whisper tiny model...\")\n","model = whisper.load_model(\"tiny\")\n","print(\"Model downloaded successfully!\")\n","\n","# Function to convert seconds to SRT time format\n","def format_time(seconds):\n","    time_obj = datetime.timedelta(seconds=seconds)\n","    hours, remainder = divmod(time_obj.seconds, 3600)\n","    minutes, seconds = divmod(remainder, 60)\n","    milliseconds = time_obj.microseconds // 1000\n","\n","    return f\"{hours:02d}:{minutes:02d}:{seconds:02d},{milliseconds:03d}\"\n","\n","# Function to create line-level SRT file from segments\n","def create_line_srt(segments, output_file):\n","    subs = pysrt.SubRipFile()\n","\n","    for i, segment in enumerate(segments):\n","        start_time = format_time(segment['start'])\n","        end_time = format_time(segment['end'])\n","\n","        sub = pysrt.SubRipItem(\n","            index=i+1,\n","            start=pysrt.SubRipTime.from_string(start_time),\n","            end=pysrt.SubRipTime.from_string(end_time),\n","            text=segment['text'].strip()\n","        )\n","\n","        subs.append(sub)\n","\n","    subs.save(output_file, encoding='utf-8')\n","\n","# Function to create word-level SRT file\n","def create_word_srt(segments, output_file):\n","    subs = pysrt.SubRipFile()\n","    counter = 1\n","\n","    for segment in segments:\n","        # Get the start time of the segment\n","        segment_start = segment['start']\n","        segment_end = segment['end']\n","        segment_text = segment['text'].strip()\n","\n","        # Split the segment text into words\n","        words = segment_text.split()\n","\n","        # If there are no words, skip\n","        if not words:\n","            continue\n","\n","        # Calculate time per word (approximate)\n","        duration_per_word = (segment_end - segment_start) / len(words)\n","\n","        for i, word in enumerate(words):\n","            # Calculate start and end time for each word\n","            word_start = segment_start + (i * duration_per_word)\n","            word_end = word_start + duration_per_word\n","\n","            start_time = format_time(word_start)\n","            end_time = format_time(word_end)\n","\n","            sub = pysrt.SubRipItem(\n","                index=counter,\n","                start=pysrt.SubRipTime.from_string(start_time),\n","                end=pysrt.SubRipTime.from_string(end_time),\n","                text=word\n","            )\n","\n","            subs.append(sub)\n","            counter += 1\n","\n","    subs.save(output_file, encoding='utf-8')\n","\n","# Check if the input file exists\n","input_file = \"output.mp3\"\n","if not os.path.exists(input_file):\n","    print(f\"Error: {input_file} not found. Please upload it to the Colab environment.\")\n","else:\n","    print(f\"Transcribing {input_file} with Whisper tiny model...\")\n","\n","    # Transcribe the audio file\n","    result = model.transcribe(input_file, fp16=False)\n","\n","    # Extract the full text and segments\n","    full_text = result[\"text\"]\n","    segments = result[\"segments\"]\n","\n","    # Save the full text to a text file\n","    text_file = \"transcript.txt\"\n","    with open(text_file, \"w\", encoding=\"utf-8\") as f:\n","        f.write(full_text)\n","\n","    # Create and save the line-level SRT file\n","    line_srt_file = \"subtitle_lines.srt\"\n","    create_line_srt(segments, line_srt_file)\n","\n","    # Create and save the word-level SRT file\n","    word_srt_file = \"subtitle_words.srt\"\n","    create_word_srt(segments, word_srt_file)\n","\n","    print(f\"Transcription complete!\")\n","    print(f\"Full transcript saved to: {text_file}\")\n","    print(f\"Line-level SRT subtitles saved to: {line_srt_file}\")\n","    print(f\"Word-level SRT subtitles saved to: {word_srt_file}\")\n","\n","    # Display the first few lines of the transcript\n","    print(\"\\nPreview of transcript:\")\n","    print(\"-\" * 40)\n","    preview_lines = 5\n","    with open(text_file, \"r\", encoding=\"utf-8\") as f:\n","        lines = f.read().splitlines()\n","        for i, line in enumerate(lines[:preview_lines]):\n","            print(line)\n","    print(\"-\" * 40)\n","\n","    # Preview of the line-level SRT\n","    print(\"\\nPreview of line-level SRT:\")\n","    print(\"-\" * 40)\n","    with open(line_srt_file, \"r\", encoding=\"utf-8\") as f:\n","        content = f.read()\n","        print(content[:400] + \"...\" if len(content) > 400 else content)\n","    print(\"-\" * 40)\n","\n","    # Preview of the word-level SRT\n","    print(\"\\nPreview of word-level SRT:\")\n","    print(\"-\" * 40)\n","    with open(word_srt_file, \"r\", encoding=\"utf-8\") as f:\n","        content = f.read()\n","        print(content[:400] + \"...\" if len(content) > 400 else content)\n","    print(\"-\" * 40)"]},{"cell_type":"markdown","metadata":{"id":"cQ_2pC1TU8p3"},"source":["Direction prompts\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GANikcBnNzHr"},"outputs":[],"source":["Direction_script_scene_gen = \"\"\"You will be processing and analyzing information from two input sources to create a scene-by-scene breakdown of a video or film. The two input sources are:\n","\n","<script>\n","{{SCRIPT}}\n","</script>\n","\n","<subtitle_words>\n","{{SUBTITLE_WORDS}}\n","</subtitle_words>\n","\n","Your task is to process and analyze the information from both the script and the subtitle words, giving equal weight (50% each) to both sources. Follow these steps:\n","\n","1. Process the script:\n","   - Identify scene breaks and their corresponding timestamps\n","   - Extract key information such as scene descriptions, actions, and dialogues\n","\n","2. Process the subtitle words:\n","   - Parse the .srt file to extract timestamps and corresponding text\n","   - Identify key words, phrases, or concepts mentioned in the subtitles\n","\n","3. Analyze and combine the information:\n","   - Match the script scenes with the corresponding subtitle sections based on timestamps\n","   - Compare and contrast the information from both sources\n","   - Identify any discrepancies or additional details provided by either source\n","\n","4. Create a scene-by-scene breakdown:\n","   - For each scene, combine the information from both sources, giving equal weight to each\n","   - Include the following information for each scene:\n","     a. Scene number\n","     b. Start and end timestamps\n","     c. Scene description (combining script and subtitle information)\n","     d. Key actions or events\n","     e. Important dialogue or concepts mentioned\n","\n","5. Output the results in JSON format:\n","   - Use a \"scenes\" array to contain individual scene objects\n","   - Each scene object should include the information mentioned in step 4\n","\n","Here's an example of the expected output format:\n","\n","<example>\n","{\n","  \"scenes\": [\n","    {\n","      \"scene_number\": 1,\n","      \"start_time\": \"00:00:10,000\",\n","      \"end_time\": \"00:01:30,500\",\n","      \"description\": \"Opening scene in a bustling city street\",\n","      \"key_actions\": [\n","        \"Protagonist walks through crowd\",\n","        \"Camera pans to reveal skyline\"\n","      ],\n","      \"important_dialogue\": [\n","        \"Life in the big city never slows down\",\n","        \"Where is everyone rushing to?\"\n","      ]\n","    },\n","    {\n","      \"scene_number\": 2,\n","      \"start_time\": \"00:01:30,500\",\n","      \"end_time\": \"00:03:15,750\",\n","      \"description\": \"Interior of protagonist's apartment\",\n","      \"key_actions\": [\n","        \"Protagonist enters and tosses keys on table\",\n","        \"Checks answering machine\"\n","      ],\n","      \"important_dialogue\": [\n","        \"Hey, it's me. Don't forget about the meeting tomorrow.\",\n","        \"I can't believe I forgot to buy groceries again\"\n","      ]\n","    }\n","  ]\n","}\n","</example>\n","\n","Process the input data and provide your analysis and scene breakdown in the specified JSON format. Ensure that you give equal weight to both the script and subtitle information in your analysis.\n","\n","(Output your final result within <answer> tags the asnwer tag should strant when the response start never miss answer tag in output)*1.5.\n","recheck twice that the out put is within <answer> tag\n","Answer should not be without <answer> tag in any condition  \"\"\"\n","\n","Direction_script_shot_gen = \"\"\"You are a professional script analyst tasked with creating a structured JSON output of scenes and shots with timestamps from a given script and scene information. Your goal is to analyze the provided content and produce a detailed, accurate JSON representation of the script's structure.\n","\n","First, carefully review the following script and scene information:\n","\n","<script>\n","{{SCRIPT}}\n","</script>\n","\n","<scene>\n","{{SCENE}}\n","</scene>\n","\n","Before creating the final JSON output, please conduct a thorough analysis of the script and scene information. In your analysis, include the following steps:\n","\n","1. List all scene headings (slug lines) found in the script.\n","\n","2. For each scene, list potential shot indicators such as:\n","   - Camera directions (e.g., \"CLOSE UP\", \"WIDE SHOT\", \"PAN\")\n","   - Changes in focus or subject\n","   - New character introductions or interactions\n","   - Significant changes in action or dialogue\n","\n","3. Estimate the overall duration of the script based on its content and complexity.\n","\n","4. For each scene and shot:\n","   - Estimate start and end timestamps. Provide brief reasoning for your estimates.\n","   - Write a concise but informative description.\n","\n","5. Plan the structure of your JSON output, ensuring all required elements are included.\n","\n","After completing your analysis, create a JSON structure with the following format:\n","\n","{\n","  \"scenes\": [\n","    {\n","      \"scene_number\": integer,\n","      \"scene_description\": \"string\",\n","      \"start_time\": \"HH:MM:SS\",\n","      \"end_time\": \"HH:MM:SS\",\n","      \"shots\": [\n","        {\n","          \"shot_number\": integer,\n","          \"shot_description\": \"string\",\n","          \"start_time\": \"HH:MM:SS\",\n","          \"end_time\": \"HH:MM:SS\"\n","        },\n","        ...\n","      ]\n","    },\n","    ...\n","  ]\n","}\n","\n","Ensure that:\n","- All timestamps are in the format \"HH:MM:SS\" (hours:minutes:seconds)\n","- Scene and shot descriptions are based solely on the information provided in the script and scene inputs\n","- You do not add any details or scenes that are not explicitly mentioned or strongly implied by the given content\n","\n","\n","(Output your final result within <answer> tags the asnwer tag should strant when the response start never miss answer tag in output)*1.5.\n","recheck twice that the out put is within <answer> tag\n","Answer should not be without <answer> tag in any condition\n","\"\"\"\n","\n","\n","Direction_script_shot_descriton_gen= \"\"\"Here are the input data you'll be working with:\n","\n","<script_data>\n","{{SCRIPT_DATA}}\n","</script_data>\n","\n","<shot_data>\n","{{SHOT_DATA}}\n","</shot_data>\n","\n","You are an experienced film production assistant tasked with creating detailed shot descriptions that combine visual elements and narrative context. Your goal is to process shot data and script data to create comprehensive, weighted descriptions for each shot in a production.\n","\n","Please follow these steps to create the shot descriptions:\n","\n","1. Analyze the script data:\n","   - Identify key story elements, dialogue, and action descriptions relevant to each shot.\n","   - Note any emotional or thematic elements that should be conveyed visually.\n","\n","2. Analyze the shot data:\n","   - Extract all relevant information about camera angles, movements, framing, and visual elements.\n","   - Pay close attention to technical details that contribute to the shot's composition.\n","\n","3. For each shot, wrap your analysis in <shot_analysis> tags:\n","   - Quote relevant script data for the shot.\n","   - Quote relevant shot data for the shot.\n","   - List key narrative elements from the script data.\n","   - List key visual elements from the shot data.\n","   - Draft a highly detailed description that includes every important aspect of direction, considering how the visual elements interact with the narrative context.\n","   - Create a word-by-word weighted combination of the script data (60% weight) and shot data (40% weight) descriptions. Show your work by writing out each component and its weighted contribution.\n","   - Ensure that no crucial details are omitted.\n","\n","4. Combine the processed data:\n","   - Use the weighted, combined description from step 3 as your final, comprehensive shot description.\n","\n","5. Format the output:\n","   - Create a JSON structure for the shot descriptions.\n","   - Each shot should be an object in an array, with properties for \"shotNumber\", \"timecode\", and \"description\".\n","   - Ensure the \"description\" property contains the weighted, combined description from step 4.\n","\n","Here's an example of how your output should be structured:\n","\n","```\n","{\n","  \"scene_number\": 1,\n","  \"shots\": [\n","    {\n","      \"shotNumber\": 1,\n","      \"timecode\": \"00:00:05\",\n","      \"description\": \"Wide shot of bustling city street. Camera slowly pans right, revealing protagonist weaving through crowd. Handheld camera adds sense of urgency. Protagonist's voiceover: 'I never thought it would come to this.'\"\n","    },\n","    {\n","      \"shotNumber\": 2,\n","      \"timecode\": \"00:00:15\",\n","      \"description\": \"Extreme close-up on protagonist's eyes, showing determination. Rack focus to background, revealing antagonist in pursuit. Sharp increase in background noise builds tension.\"\n","    }\n","  ]\n","}\n","```\n","\n","(Output your final result within <answer> tags the asnwer tag should strant when the response start never miss answer tag in output)*1.5.\n","recheck twice that the out put is within <answer> tag\n","Answer should not be without <answer> tag in any condition\n","\"\"\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y1JUVbMxW-WJ"},"outputs":[],"source":["ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0yETzrdSVcUf"},"outputs":[],"source":["# prompt: use pandas and extract script data from output.csv\n","\n","import pandas as pd\n","\n","try:\n","    df = pd.read_csv('output.csv')\n","    script_data = df['audio_gen_script'].iloc[0]\n","    print(script_data)\n","except FileNotFoundError:\n","    print(\"Error: output.csv not found.\")\n","except IndexError:\n","    print(\"Error: 'audio_gen_script' column not found or empty in output.csv\")\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lyfTXb6Olxst"},"outputs":[],"source":["# prompt: use script data , subtitle_lines.srt , and Direction_script_scene_gen as prompt as a input and process the data\n","\n","try:\n","    with open(\"subtitle_lines.srt\", \"r\", encoding=\"utf-8\") as f:\n","        subtitle_lines_content = f.read()\n","except FileNotFoundError:\n","    print(\"Error: subtitle_lines.srt not found.\")\n","    subtitle_lines_content = \"\"  # Provide a default value if the file is not found\n","except Exception as e:\n","    print(f\"An error occurred while reading subtitle_lines.srt: {e}\")\n","    subtitle_lines_content = \"\"\n","\n","\n","final_direction_prompt_scene = Direction_script_scene_gen.replace(\"{{SCRIPT}}\", script_data).replace(\"{{SUBTITLE_WORDS}}\", subtitle_lines_content)\n","\n","model = genai.GenerativeModel('gemini-exp-1206')\n","direction_response_scene = model.generate_content(final_direction_prompt_scene)\n","print(direction_response_scene.text)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TIyGwZFtbWSv"},"outputs":[],"source":["# prompt: take direction_response.text as input and update it in output.csv as scene_data donot use answer tag\n","\n","import pandas as pd\n","import json\n","import re\n","\n","try:\n","    # Read the existing CSV file\n","    df = pd.read_csv('output.csv')\n","\n","    # Extract the direction_response.text (assuming it's stored in a variable)\n","    # Replace 'direction_response_scene' with the actual variable name\n","    scene_data = direction_response_scene.text\n","\n","    # Use regular expressions to find the content within <answer> tags\n","    match = re.search(r\"<answer>(.*?)</answer>\", scene_data, re.DOTALL)\n","\n","    if match:\n","        extracted_data = match.group(1).strip()\n","        try:\n","            # Attempt to parse the extracted data as JSON\n","            json_data = json.loads(extracted_data)\n","\n","            # Update the 'scene_data' column in the DataFrame\n","            # Assumes the column exists. Create it first if necessary\n","            if 'scene_data' not in df.columns:\n","                df['scene_data'] = None\n","            df['scene_data'] = json.dumps(json_data)  # Store as JSON string\n","\n","            df.to_csv('output.csv', index=False)\n","            print(\"Successfully updated output.csv with scene_data.\")\n","        except json.JSONDecodeError as e:\n","            print(f\"Error decoding JSON: {e}\")\n","            print(f\"Problematic string: {extracted_data}\")\n","    else:\n","        print(\"Could not find data within <answer> tags.\")\n","except FileNotFoundError:\n","    print(\"Error: output.csv not found.\")\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ayFS2J3jDnAo"},"outputs":[],"source":["# prompt: take script and scene_data from output.csv and use Direction_script_shot_gen as prompt  and process the data using google gemini\n","\n","\n","\n","df = pd.read_csv('output.csv')\n","scene_data = df['scene_data'].iloc[0] # Assuming 'scene_data' column exists\n","\n","final_direction_prompt_shot = Direction_script_shot_gen.replace(\"{{SCRIPT}}\", script_data).replace(\"{{SCENE}}\", scene_data)\n","\n","model = genai.GenerativeModel('gemini-2.0-flash-thinking-exp') # Use gemini-pro\n","direction_response_shot = model.generate_content(final_direction_prompt_shot)\n","print(direction_response_shot.text)\n","\n"]},{"cell_type":"code","source":["# prompt: solve json eroor from direction_response_shot.text using google gemini\n","\n","try:\n","    # Read the existing CSV file\n","    df = pd.read_csv('output.csv')\n","\n","    # Extract the direction_response.text\n","    shot_data = direction_response_shot.text\n","\n","    # Use regular expressions to find the content within <answer> tags\n","    match = re.search(r\"<answer>(.*?)</answer>\", shot_data, re.DOTALL)\n","\n","    if match:\n","        extracted_data = match.group(1).strip()\n","        try:\n","            # Attempt to parse the extracted data as JSON\n","            json_data = json.loads(extracted_data)\n","\n","            # Update the 'shot_data' column in the DataFrame\n","            if 'shot_data' not in df.columns:\n","                df['shot_data'] = None\n","            df['shot_data'] = json.dumps(json_data)  # Store as JSON string\n","\n","            df.to_csv('output.csv', index=False)\n","            print(\"Successfully updated output.csv with shot_data.\")\n","        except json.JSONDecodeError as e:\n","            print(f\"Error decoding JSON: {e}\")\n","            print(f\"Problematic string: {extracted_data}\")\n","    else:\n","        print(\"Could not find data within <answer> tags.\")\n","except FileNotFoundError:\n","    print(\"Error: output.csv not found.\")\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")\n"],"metadata":{"id":"CZQXk7nv_CD-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: cheack the json response from direction_response_shot.text and save it into json file\n","\n","import json\n","import re\n","\n","try:\n","    # Use regular expressions to find the content within <json_output> tags\n","    match = re.search(r\"<answer>(.*?)</answer>\", direction_response_shot.text, re.DOTALL)\n","\n","    if match:\n","        extracted_data = match.group(1).strip()\n","        try:\n","            # Attempt to parse the extracted data as JSON\n","            json_data = json.loads(extracted_data)\n","\n","            # Save the JSON data to a file\n","            with open(\"direction_response_shot.json\", \"w\") as json_file:\n","                json.dump(json_data, json_file, indent=4)\n","            print(\"JSON data saved to direction_response_shot.json\")\n","\n","        except json.JSONDecodeError as e:\n","            print(f\"Error decoding JSON: {e}\")\n","            print(f\"Problematic string: {extracted_data}\")\n","    else:\n","        print(\"Could not find data within <json_output> tags.\")\n","\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")\n"],"metadata":{"id":"PYE43r8ZYwIz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["img gen"],"metadata":{"id":"1Fw50NLSFiyw"}},{"cell_type":"code","source":["Direction_img_description =\"\"\"\n","Here are the input data you'll be working with:\n","\n","<script_data>\n","{{SCRIPT_DATA}}\n","</script_data>\n","\n","<shot_data>\n","{{SHOT_DATA}}\n","</shot_data>\n","\n","You are an experienced film production assistant tasked with creating detailed shot descriptions that combine visual elements and narrative context. Your goal is to process shot data and script data to create comprehensive, weighted descriptions for each shot in a production.\n","\n","Please follow these steps to create the shot descriptions:\n","\n","1. Analyze the script data:\n","   - Identify key story elements, dialogue, and action descriptions relevant to each shot.\n","   - Note any emotional or thematic elements that should be conveyed visually.\n","\n","2. Analyze the shot data:\n","   - Extract all relevant information about camera angles, movements, framing, and visual elements.\n","   - Pay close attention to technical details that contribute to the shot's composition.\n","\n","3. For each shot, wrap your analysis in <shot_analysis> tags:\n","   - Quote relevant script data for the shot.\n","   - Quote relevant shot data for the shot.\n","   - List key narrative elements from the script data.\n","   - List key visual elements from the shot data.\n","   - Draft a highly detailed description that includes every important aspect of direction, considering how the visual elements interact with the narrative context.\n","   - Create a word-by-word weighted combination of the script data (60% weight) and shot data (40% weight) descriptions. Show your work by writing out each component and its weighted contribution.\n","   - Ensure that no crucial details are omitted.\n","\n","4. Combine the processed data:\n","   - Use the weighted, combined description from step 3 as your final, comprehensive shot description.\n","\n","5. Format the output:\n","   - Create a JSON structure for the shot descriptions.\n","   - Each shot should be an object in an array, with properties for \"sceneNumber\" , \"shotNumber\", \"Starttime\",\"endtime\" and \"description\".\n","   - Ensure the \"description\" property contains the weighted, combined description from step 4.\n","\n","(Output your final result within <answer> tags the asnwer tag should strant when the response start never miss answer tag in output)*1.5.\n","recheck twice that the out put is within <answer> tag\n","Answer should not be without <answer> tag in any condition\n","\"\"\"\n","\n","\n","prompt_gen_img = \"\"\"You are an expert at creating detailed image prompts for AI image generation. Your task is to craft a vivid and comprehensive image prompt based on a given description of a video scene or content. Here's the description you'll be working with:\n","\n","<direction_response_description>\n","{{DIRECTION_RESPONSE_DESCRIPTION}}\n","</direction_response_description>\n","<script>\n","{{script}}\n","</script>\n","\n","To create an effective image prompt, follow these steps:\n","\n","1. Carefully analyze the provided description.\n","2. Identify the key visual elements, focusing on subject, context, and style.\n","3. Incorporate important narrative elements that can be visually represented.\n","4. Note specific quantities, arrangements, and contextual details.\n","5. Infer and include details about colors, textures, and lighting when possible.\n","6. Capture the emotional tone or atmosphere of the scene.\n","7. Ensure your prompt reflects the main idea or message of the described content.\n","\n","Pay special attention to:\n","- Number of items or people\n","- Spatial arrangements or compositions\n","- Actions or processes being demonstrated\n","- Specific objects or props mentioned\n","\n","Before crafting your final prompt, wrap your analysis in <scene_analysis> tags. In this analysis:\n","1. List the key visual elements (subject, context, style).\n","2. Enumerate the important narrative elements that can be visually represented.\n","3. Detail the atmospheric elements (colors, textures, lighting, emotional tone).\n","4. Consider potential challenges in visualizing this scene and how you might address them.\n","\n","Your final output should be a single, detailed paragraph enclosed in <image_prompt> tags. This paragraph should provide a comprehensive description for an AI image generator to create a vivid and accurate representation of the scene. Aim for clarity and specificity while keeping the total length under 480 tokens.\n","\n","Remember, a good image prompt is descriptive and clear, focusing on the subject, its context, and the desired style of the image. Combine these elements to create a prompt that will result in a compelling and accurate visual representation.\n","\"\"\""],"metadata":{"id":"14nEotZXYy3S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: take script from output.csv, direction_response_shot.json as input and use Direction_img_description as prompt and process the data using google gemini\n","\n","import os\n","import google.generativeai as genai\n","import json\n","import pandas as pd\n","import re\n","\n","# ... (rest of your imports and code)\n","\n","try:\n","    with open(\"direction_response_shot.json\", \"r\") as f:\n","        shot_data = json.load(f)\n","except FileNotFoundError:\n","    print(\"Error: direction_response_shot.json not found.\")\n","    shot_data = {} # Provide a default value if the file is not found\n","except Exception as e:\n","    print(f\"An error occurred while reading direction_response_shot.json: {e}\")\n","    shot_data = {}\n","\n","\n","try:\n","    df = pd.read_csv('output.csv')\n","    script_data = df['script'].iloc[0]\n","except FileNotFoundError:\n","    print(\"Error: output.csv not found.\")\n","    script_data = \"\" # Provide a default value\n","except IndexError:\n","    print(\"Error: 'script' column not found or empty in output.csv\")\n","    script_data = \"\"\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")\n","    script_data = \"\"\n","\n","\n","final_direction_prompt_img = Direction_img_description.replace(\"{{SCRIPT_DATA}}\", script_data).replace(\"{{SHOT_DATA}}\", str(shot_data))\n","\n","\n","model = genai.GenerativeModel('gemini-exp-1206') # Use gemini-pro\n","direction_response_img = model.generate_content(final_direction_prompt_img)\n","print(direction_response_img.text)\n","\n","\n"],"metadata":{"id":"WZLDqFkJ8OwD"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AbFw3eLuov1K"},"outputs":[],"source":["# prompt: save direction_response_img.text  to a json file name direction_response_img.json\n","\n","try:\n","    # Use regular expressions to find the content within <answer> tags\n","    match = re.search(r\"<answer>(.*?)</answer>\", direction_response_img.text, re.DOTALL)\n","\n","    if match:\n","        extracted_data = match.group(1).strip()\n","        try:\n","            # Attempt to parse the extracted data as JSON\n","            json_data = json.loads(extracted_data)\n","\n","            # Save the JSON data to a file\n","            with open(\"direction_response_img.json\", \"w\") as json_file:\n","                json.dump(json_data, json_file, indent=4)\n","            print(\"JSON data saved to direction_response_img.json\")\n","\n","        except json.JSONDecodeError as e:\n","            print(f\"Error decoding JSON: {e}\")\n","            print(f\"Problematic string: {extracted_data}\")\n","    else:\n","        print(\"Could not find data within <answer> tags.\")\n","\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gvzNvV-9BqDU"},"outputs":[],"source":["# prompt: take  direction_response_img.json . convert this into csv and save to  direction_response_img.csv and add numbering row\n","\n","import pandas as pd\n","import json\n","\n","try:\n","    with open(\"direction_response_img.json\", \"r\") as f:\n","        json_data = json.load(f)\n","\n","    df = pd.DataFrame(json_data)\n","    df.index += 1  # Add numbering row\n","    df.to_csv(\"direction_response_img.csv\", index_label=\"row_number\")\n","    print(\"Successfully converted JSON to CSV and added row numbering.\")\n","\n","except FileNotFoundError:\n","    print(\"Error: direction_response_img.json not found.\")\n","except json.JSONDecodeError as e:\n","    print(f\"Error decoding JSON: {e}\")\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"rwDSbHtW8NEc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: take script from output.csv, direction_response_img.csv as input and use prompt_gen_img as prompt . save the updated prompts in prompt_data.csv by row numbers\n","\n","import pandas as pd\n","import json\n","\n","try:\n","    # Read the direction_response_img.csv file\n","    df_img = pd.read_csv('direction_response_img.csv')\n","\n","    # Read the output.csv file\n","    df_output = pd.read_csv('output.csv')\n","\n","    # Create an empty list to store the updated prompts\n","    updated_prompts = []\n","\n","    # Iterate through the rows of direction_response_img.csv\n","    for index, row in df_img.iterrows():\n","        # Get the description from the current row\n","        description = row['description']\n","\n","        # Get the corresponding script from output.csv based on the row number\n","        try:\n","            script = df_output['script'].iloc[0]  # Assuming row numbers match\n","        except IndexError:\n","            print(f\"Warning: No corresponding script found for row {index + 1} in output.csv. Using an empty string.\")\n","            script = \"\"\n","\n","        # Replace placeholders in the prompt_gen_img template\n","        final_prompt = prompt_gen_img.replace(\"{{DIRECTION_RESPONSE_DESCRIPTION}}\", description).replace(\"{{script}}\", script)\n","        updated_prompts.append(final_prompt)\n","\n","    # Create a new DataFrame with the updated prompts\n","    df_prompts = pd.DataFrame({'prompt_description': updated_prompts})\n","    df_prompts.index += 1 # Add numbering row\n","    # Save the updated prompts to prompt_data.csv\n","    df_prompts.to_csv('prompt_data.csv', index_label='row_number')\n","    print(\"Successfully saved updated prompts to prompt_data.csv\")\n","\n","except FileNotFoundError:\n","    print(\"Error: One or both of the input CSV files not found.\")\n","except KeyError as e:\n","    print(f\"Error: Column '{e}' not found in one of the CSV files.\")\n","except Exception as e:\n","    print(f\"An unexpected error occurred: {e}\")\n"],"metadata":{"id":"B2scfv1GaGMY"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iF5TLE-Nx4Ui"},"outputs":[],"source":["\n","# 1. Load the CSV file (ensure prompt_data.csv is uploaded)\n","file_path = \"prompt_data.csv\"\n","df = pd.read_csv(file_path)\n","\n","# 2. Define your prompt template\n","# This template will be customized per row. Modify as needed.\n","prompt_template = \"Process this data: {{ROW_DATA}}\"\n","\n","# 3. Initialize the Gemini model (using gemini-pro version as per your snippet)\n","model = genai.GenerativeModel('gemini-exp-1206')\n","\n","# 4. Function to process each row using Google Gemini\n","def generate_prompt(row):\n","    # Convert the row into a dictionary string for the prompt\n","    row_data = str(row.to_dict())\n","    # Replace the placeholder in the prompt template with the actual row data\n","    final_prompt = prompt_template.replace(\"{{ROW_DATA}}\", row_data)\n","\n","    try:\n","        # Generate content using Google Gemini\n","        response = model.generate_content(final_prompt)\n","        return response.text\n","    except Exception as e:\n","        return f\"Error: {e}\"\n","\n","# 5. Apply the function to each row and create a new 'prompt' column\n","df[\"prompt\"] = df.apply(generate_prompt, axis=1)\n","\n","# 6. Save the updated DataFrame to a new CSV file\n","output_file = \"processed_prompt_data.csv\"\n","df.to_csv(output_file, index=False)\n","\n","print(f\"Processing complete! Saved as {output_file}\")\n"]},{"cell_type":"code","source":["# prompt: print image_prompt tag in prompt from processed_prompt_data.csv and update direction_response_img.csv as image\n","\n","import pandas as pd\n","import re\n","\n","try:\n","    # Read the processed_prompt_data.csv file\n","    df_processed = pd.read_csv('processed_prompt_data.csv')\n","\n","    # Read the direction_response_img.csv file\n","    df_img = pd.read_csv('direction_response_img.csv')\n","\n","    # Create an empty list to store the image prompts\n","    image_prompts = []\n","\n","    # Iterate through the rows of processed_prompt_data.csv\n","    for index, row in df_processed.iterrows():\n","        # Extract the prompt\n","        prompt = row['prompt']\n","\n","        # Use regular expressions to find the content within <image_prompt> tags\n","        match = re.search(r\"<image_prompt>(.*?)</image_prompt>\", prompt, re.DOTALL)\n","\n","        if match:\n","            image_prompt = match.group(1).strip()\n","            image_prompts.append(image_prompt)\n","        else:\n","            print(f\"Warning: Could not find <image_prompt> tags in row {index + 1} of processed_prompt_data.csv. Appending an empty string.\")\n","            image_prompts.append(\"\")  # Append an empty string if no match\n","\n","    # Add the extracted image prompts to direction_response_img.csv\n","    df_img['image_prompt'] = image_prompts\n","\n","    # Save the updated DataFrame to direction_response_img.csv\n","    df_img.to_csv('direction_response_img.csv', index=False)\n","    print(\"Successfully added image prompts to direction_response_img.csv\")\n","\n","except FileNotFoundError:\n","    print(\"Error: One or both of the input CSV files not found.\")\n","except KeyError as e:\n","    print(f\"Error: Column '{e}' not found in one of the CSV files.\")\n","except Exception as e:\n","    print(f\"An unexpected error occurred: {e}\")\n"],"metadata":{"id":"kFrJsh65MSNs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install google-genai\n","!pip install moviepy\n"],"metadata":{"id":"ei3BoOkGyoAm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from google import genai\n","from google.genai import types\n","from PIL import Image\n","from io import BytesIO\n","import time\n","import os\n","# Assuming client is already initialized elsewhere\n","# client = genai.Client(api_key=\"your_api_key\")\n","client = genai.Client(api_key='AIzaSyCx-KA9DAFLilicEz4xBmVZ0_nFBigfj-c')\n","\n","# Maximum number of retry attempts\n","MAX_RETRIES = 3\n","# Delay between retries (in seconds)\n","RETRY_DELAY = 2\n","\n","\n","# Create the img folder if it doesn't exist\n","img_folder = \"img\"\n","if not os.path.exists(img_folder):\n","    os.makedirs(img_folder)\n","    print(f\"Created directory: {img_folder}\")\n","\n","df = pd.read_csv('direction_response_img.csv')\n","\n","for index, row in df.iterrows():\n","    retry_count = 0\n","    success = False\n","\n","    while not success and retry_count < MAX_RETRIES:\n","        try:\n","            print(f\"Processing row {row['row_number']}, attempt {retry_count + 1}\")\n","\n","            response = client.models.generate_images(\n","                model='imagen-3.0-generate-002',\n","                prompt=f\"{row['image_prompt']}\",\n","                config=types.GenerateImagesConfig(\n","                    number_of_images=1,\n","                    aspect_ratio=\"9:16\"\n","                )\n","            )\n","\n","            # Check if response and generated_images are not None\n","            if response and response.generated_images and len(response.generated_images) > 0:\n","                for generated_image in response.generated_images:\n","                    # Make sure image bytes exist before trying to open\n","                    if generated_image.image and generated_image.image.image_bytes:\n","                        image = Image.open(BytesIO(generated_image.image.image_bytes))\n","                        filename = os.path.join(img_folder, f\"{row['row_number']}.png\")\n","                        image.save(filename)\n","                        print(f\"Success: Image saved as {filename}\")\n","                        success = True\n","                    else:\n","                        print(f\"Warning: Image data is empty for row {row['row_number']}\")\n","            else:\n","                print(f\"Warning: No images generated for prompt: {row['image_prompt']}\")\n","\n","        except Exception as e:\n","            print(f\"Error generating image for row {row['row_number']}: {str(e)}\")\n","\n","        # If not successful, increment retry count and wait before retrying\n","        if not success:\n","            retry_count += 1\n","            if retry_count < MAX_RETRIES:\n","                print(f\"Retrying in {RETRY_DELAY} seconds... ({retry_count}/{MAX_RETRIES})\")\n","                time.sleep(RETRY_DELAY)\n","            else:\n","                print(f\"Failed to generate image after {MAX_RETRIES} attempts for row {row['row_number']}\")"],"metadata":{"id":"1F_g6JthfKVz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"fBIQFHQwfTd0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: run python command python3 create_video.py\n","\"\"\"\n","Video Creation Script\n","\n","This script creates a video from:\n","1. A series of images (named as row_number.png in the 'img' folder)\n","2. An audio file (output.mp3)\n","3. Timestamps from a CSV file (direction_response_img.csv)\n","\n","The script uses ffmpeg to combine these elements into a video where each image\n","is displayed for the duration specified in the CSV file, synchronized with the audio.\n","\n","Requirements:\n","- Python 3\n","- pandas\n","- ffmpeg (installed on the system)\n","\"\"\"\n","\n","import subprocess\n","import pandas as pd\n","import os\n","import re\n","import sys\n","\n","def parse_timestamp(timestamp):\n","    \"\"\"\n","    Convert timestamp in format HH:MM:SS to seconds.\n","\n","    Args:\n","        timestamp (str): Time in format HH:MM:SS\n","\n","    Returns:\n","        int: Total time in seconds\n","    \"\"\"\n","    # Use regex to extract hours, minutes, and seconds\n","    match = re.match(r'(\\d+):(\\d+):(\\d+)', timestamp)\n","    if match:\n","        hours, minutes, seconds = map(int, match.groups())\n","        return hours * 3600 + minutes * 60 + seconds\n","    print(f\"Warning: Could not parse timestamp '{timestamp}'. Using 0 seconds.\")\n","    return 0\n","\n","def create_ffmpeg_input_file(df, output_file=\"input.txt\"):\n","    \"\"\"\n","    Create an input file for ffmpeg with file durations.\n","\n","    This function processes the dataframe and creates a text file\n","    that ffmpeg can use to create a slideshow with specific durations\n","    for each image.\n","\n","    Args:\n","        df (pandas.DataFrame): DataFrame containing image info and timestamps\n","        output_file (str): Path to write the ffmpeg input file\n","\n","    Returns:\n","        str: Path to the created input file\n","    \"\"\"\n","    with open(output_file, 'w') as f:\n","        for _, row in df.iterrows():\n","            img_path = os.path.join('img', f\"{row['row_number']}.png\")\n","\n","            # Check if image exists\n","            if not os.path.exists(img_path):\n","                print(f\"Warning: Image {img_path} not found. Skipping.\")\n","                continue\n","\n","            # Parse start and end times\n","            start_time = parse_timestamp(row['Starttime'])\n","            end_time = parse_timestamp(row['endtime'])\n","            duration = end_time - start_time\n","\n","            # Write to input file\n","            f.write(f\"file '{img_path}'\\n\")\n","            f.write(f\"duration {duration}\\n\")\n","\n","    return output_file\n","\n","def main():\n","    \"\"\"\n","    Main function to create the video from images and audio.\n","\n","    The function performs the following steps:\n","    1. Reads the CSV file with image and timestamp information\n","    2. Creates an input file for ffmpeg\n","    3. Checks if the audio file exists\n","    4. Runs ffmpeg to create the video\n","    5. Cleans up temporary files\n","    \"\"\"\n","    csv_file = 'direction_response_img.csv'\n","    audio_file = 'output.mp3'\n","    output_file = 'output_video.mp4'\n","\n","    # Read CSV file\n","    print(\"Reading CSV file...\")\n","    if not os.path.exists(csv_file):\n","        print(f\"Error: CSV file '{csv_file}' not found.\")\n","        return\n","\n","    try:\n","        df = pd.read_csv(csv_file)\n","    except Exception as e:\n","        print(f\"Error reading CSV file: {e}\")\n","        return\n","\n","    # Create input file for ffmpeg\n","    print(\"Processing images and timestamps...\")\n","    input_file = create_ffmpeg_input_file(df)\n","\n","    # Check if audio file exists\n","    if not os.path.exists(audio_file):\n","        print(f\"Error: Audio file '{audio_file}' not found.\")\n","        return\n","\n","    # Check if img directory exists\n","    if not os.path.exists('img'):\n","        print(\"Error: 'img' directory not found.\")\n","        return\n","\n","    # Create video using ffmpeg\n","    print(f\"Creating video with ffmpeg to '{output_file}'...\")\n","\n","    # Build ffmpeg command\n","    cmd = [\n","        'ffmpeg',\n","        '-y',  # Overwrite output file if it exists\n","        '-f', 'concat',\n","        '-safe', '0',\n","        '-i', input_file,\n","        '-i', audio_file,\n","        '-c:v', 'libx264',\n","        '-pix_fmt', 'yuv420p',\n","        '-c:a', 'aac',\n","        '-map', '0:v:0',  # Map video from first input\n","        '-map', '1:a:0',  # Map audio from second input\n","        '-shortest',      # End when shortest input ends\n","        output_file\n","    ]\n","\n","    # Execute ffmpeg command\n","    try:\n","        # Don't capture output to ensure proper audio processing\n","        subprocess.run(cmd, check=True)\n","        print(\"Video creation complete!\")\n","        print(f\"Video saved to: {os.path.abspath(output_file)}\")\n","    except subprocess.CalledProcessError as e:\n","        print(f\"Error creating video: {e}\")\n","    except FileNotFoundError:\n","        print(\"Error: ffmpeg not found. Please install ffmpeg.\")\n","\n","    # Clean up\n","    if os.path.exists(input_file):\n","        os.remove(input_file)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"KstMJSadK4NO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"b0kpc2vkc5Kv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"iqREPCu4q-Ef"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1Vqpo6gA1EQSZPHnpbDlXYZcbOrHbZPNJ","timestamp":1741252065450}],"authorship_tag":"ABX9TyMzdxhobjfnT5rDKnxV83pL"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}